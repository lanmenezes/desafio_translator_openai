{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "vhjFREeZnfKM",
        "outputId": "08f6c5ad-6cbb-4b75-ee10-acd423ea59e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain-openai)\n",
            "  Downloading langchain_core-1.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.4.35)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.0.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.0-py3-none-any.whl (467 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.0 langchain-openai-1.0.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "636156ca20ec4fd882ce58ce55098e27",
              "pip_warning": {
                "packages": [
                  "langchain_core"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G1EOhD8rUNT",
        "outputId": "1ea7e849-dc24-417d-8aab-bcdcc6c1d9ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n59Qovopqrm9"
      },
      "source": [
        "## --------------------------------------\n",
        "## Primeira Parte - Traduzindo documentos\n",
        "## --------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2lftV3_gqkBj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from docx import  Document\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQG57Sn1qjxs"
      },
      "outputs": [],
      "source": [
        "subscription_key = 'DxxxxxxxGDUAb'\n",
        "endpoint = 'https://api.cognitive.microsofttranslator.com/'\n",
        "location = 'eastus'\n",
        "language_destination = 'pt-br'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "SiQD2cwvrqI8"
      },
      "outputs": [],
      "source": [
        "def translator_text(text, target_language):\n",
        "\tpath = '/translate'\n",
        "\tconstructed_url = endpoint + path\n",
        "\theaders = {\n",
        "\t'Ocp-Apim-Subscription-Key': subscription_key,\n",
        "\t'Ocp-Apim-Subscription-Region': location,\n",
        "\t'Content-type': 'application/json',\n",
        "\t'X-ClientTraceId': str(os.urandom(16))\n",
        "\n",
        "\t}\n",
        "\n",
        "\tbody = [{'text': text}]\n",
        "\tparams = {\n",
        "\t\t'api-version': '3.0',\n",
        "\t\t'from': 'en',\n",
        "\t\t'to': target_language\n",
        "\t}\n",
        "\trequest = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
        "\tresponse = request.json()\n",
        "\treturn response[0]['translations'][0]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cwFPuwjbrws0",
        "outputId": "07442cdf-3f47-4022-d59c-3be958747f8c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Eu quero ir para casa'"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translator_text(\"I wanna go home\", language_destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "TTy3BRvwupbM"
      },
      "outputs": [],
      "source": [
        "def translate_document(path):\n",
        "\tdocument = Document(path)\n",
        "\tfull_text = []\n",
        "\tfor paragraph in document.paragraphs:\n",
        "\t\ttranslated_text =  translator_text(paragraph.text, language_destination)\n",
        "\t\tfull_text.append(translated_text)\n",
        "\n",
        "\ttranslated_doc = Document()\n",
        "\tfor line in full_text:\n",
        "\t\ttranslated_doc.add_paragraph(line)\n",
        "\tpath_translated = path.replace(\".docx\", f\"{language_destination}.docx\")\n",
        "\ttranslated_doc.save(path_translated)\n",
        "\treturn path_translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SVKNuBd4usEG",
        "outputId": "0301afe6-b615-498b-e066-f5b607dbc7d5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/exemplo_musicapt-br.docx'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_file = \"/content/exemplo_musica.docx\"\n",
        "translate_document(input_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gvBtPHuqFXL"
      },
      "source": [
        "## --------------------------------\n",
        "## Segunda Parte - Traduzindo URL\n",
        "## --------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K2OaSqbjl9Sc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain_openai.chat_models.azure import AzureChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "mxenYNLfmI6H",
        "outputId": "8660a39c-93ea-40e9-db13-37f57351020e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\n\\n\\nAzure Open AI in VNet - DEV Community\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Forem Feed\\n            \\n\\n              Follow new Subforems to improve your feed\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDEV Community\\n\\nFollow\\n\\n            A space to discuss and keep up software development and manage your software career\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGamers Forem\\n\\nFollow\\n\\n            An inclusive community for gaming enthusiasts\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFuture\\n\\nFollow\\n\\n            News and discussion of science and technology such as AI, VR, cryptocurrency, quantum computing, and more.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMusic Forem\\n\\nFollow\\n\\n            From composing and gigging to gear, hot music takes, and everything in between.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nVibe Coding Forem\\n\\nFollow\\n\\n            Discussing AI software development, and showing off what we're building.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen Forem\\n\\nFollow\\n\\n            A general discussion space for the Forem community. If it doesn't have a home elsewhere, it belongs here\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPopcorn Movies and TV\\n\\nFollow\\n\\n            Movie and TV enthusiasm, criticism and everything in-between.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDUMB DEV Community\\n\\nFollow\\n\\n            Memes and software development shitposting\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDesign Community\\n\\nFollow\\n\\n            Web design, graphic design and everything in-between\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGolf Forem\\n\\nFollow\\n\\n            A community of golfers and golfing enthusiasts\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSecurity Forem\\n\\nFollow\\n\\n            Your central hub for all things security. From ethical hacking and CTFs to GRC and career development, for beginners and pros alike\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nScale Forem\\n\\nFollow\\n\\n            For engineers building software at scale. We discuss architecture, cloud-native, and SRE—the hard-won lessons you can't just Google\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nForem Core\\n\\nFollow\\n\\n            Discussing the core forem open source software project — features, bugs, performance, self-hosting.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCrypto Forem\\n\\nFollow\\n\\n            A collaborative community for all things Crypto—from Bitcoin to protocol development and DeFi to NFTs and market analysis.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nParenting\\n\\nFollow\\n\\n            A place for parents to the share the joys, challenges, and wisdom that come from raising kids. We're here for them and for each other.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMaker Forem\\n\\nFollow\\n\\n            A community for makers, hobbyists, and professionals to discuss Arduino, Raspberry Pi, 3D printing, and much more.\\n          \\n\\n\\n\\n\\nDropdown menu\\n\\n\\n\\n\\nDropdown menu\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\nNavigation menu\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n                Powered by Algolia\\n                Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Log in\\n            \\n\\n\\n            Create account\\n          \\n\\n\\n\\n\\n\\n\\n\\nDEV Community\\n\\nClose\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Add reaction\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Like\\n    \\n\\n\\n\\n\\n\\n\\n\\n      Unicorn\\n    \\n\\n\\n\\n\\n\\n\\n\\n      Exploding Head\\n    \\n\\n\\n\\n\\n\\n\\n\\n      Raised Hands\\n    \\n\\n\\n\\n\\n\\n\\n\\n      Fire\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Jump to Comments\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Save\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      Boost\\n    \\n\\n\\n\\n\\n\\n\\n\\nMore...\\n\\n\\n\\n\\n            Moderate\\n          \\n\\n\\n\\nCopy link\\nCopy link\\n\\n\\n\\nCopied to Clipboard\\n\\n\\n\\n            Share to X\\n          \\n\\n            Share to LinkedIn\\n          \\n\\n            Share to Facebook\\n          \\n\\n            Share to Mastodon\\n          \\n\\n\\n\\n\\nReport Abuse\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nKenichiro Nakamura\\n\\n                        Posted on Oct 12, 2023\\n\\n\\n\\n\\n\\n\\n\\n\\xa0\\n\\n\\n\\n\\xa0\\n\\n\\n\\n\\xa0\\n\\n\\n\\n\\xa0\\n\\n\\n\\n\\xa0\\n\\n\\n\\n                Azure Open AI in VNet\\n              \\n\\n#azure\\n#openai\\n#security\\n\\n\\n\\n\\n\\nGPT models are hosted in multiple service vendor at the moment, and Microsoft Azure is one of them.\\nEven though the models themselves are the same, there are many differences including:\\n\\ncost\\nfunctionalities\\ntype of models and versions\\ngeo location\\nsecurity\\nsupport\\netc.\\n\\nOne of the most important aspects when we use it in an Enterprise Environment is, of course, security.\\nBy using Azure network security features with Azure Open AI, customers can consume the Open AI service from and within the VNet, therefore no information is flowing in public.\\n\\n\\n\\n  Sample Deployment\\n\\nAzure Sample repo provides a sample bicep files to deploy Azure Open AI into VNet environment.\\nGitHub: openai-enterprise-iac\\nThe key features the bicep uses are:\\n\\nVNet\\nVNet integration for Web App\\nPrivate Endpoint for Azure Open AI\\nPrivate Endpoint for Cognitive Search\\nPrivate DNS Zone\\n\\nBy using these features, all the outbound traffic from the Web App only routed inside the VNet and all the names are resolved into private IP addresses. Open AI and Cognitive Search shut down the public IP address, thus there is not public interface endpoint available anymore.\\n\\n\\n\\n  Deploy\\n\\nThe bicep file will deploy following Azure Resources.\\n\\nLet's deploy and confirm how it works. I create a resource group in East US region for my own test.\\n\\n\\n\\ngit clone https://github.com/Azure-Samples/openai-enterprise-iac\\ncd openai-enterprise-iac\\naz group create -n openaitest -l eastus\\naz deployment group create -g openaitest -f .\\\\infra\\\\main.bicep\\n\\n\\n\\n\\n\\nEnter fullscreen mode\\n\\n\\nExit fullscreen mode\\n\\n\\n\\n\\n\\nOnce I run the commend above, I see the deployment started.\\nWait until the deployment completes.\\n\\n\\n\\n\\n  Test\\n\\nLet's see if the deployment was succeeded.\\n\\n\\n\\n  Azure Open AI\\n\\nLet's try public access first.\\nI could create a deployment without any issue. But when I try from the Chat playground in my Azure Portal, I see the following error.\\n\\nHow about access via the Web API?\\nFrom an advanced tool of the App Service, I login to Bash session, and first I ping the service URL.\\n\\nI see the private IP address assigned to the Private Endpoint is returend.\\nThen I use curl command to send request to the endpoint.\\n\\n\\n\\n\\n\\n\\n\\n          Top comments (0)\\n\\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal\\nTrusted User\\n\\n\\n\\n\\n\\n\\n        Create template\\n      \\nTemplates let you quickly answer FAQs or store snippets for re-use.\\n\\n\\n\\nSubmit\\nPreview\\nDismiss\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCode of Conduct\\n•\\nReport abuse\\n\\n\\n\\n\\n\\n\\n\\n        Are you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's permalink.\\n      \\n\\n\\nHide child comments as well\\n\\n\\n\\n          Confirm\\n        \\n\\n\\n For further actions, you may consider blocking this person and/or reporting abuse\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Kenichiro Nakamura\\n      \\n    \\n\\n\\n\\nFollow\\n\\n\\n\\n\\n\\n          Joined\\n        \\n\\nFeb 3, 2018\\n\\n\\n\\n\\n\\n\\n\\n\\n            More from Kenichiro Nakamura\\n\\n\\n\\n\\n              Azure ML Prompt flow: Use content safety before sending a request to LLM\\n              \\n#azure\\n#promptflow\\n#contentsafety\\n\\n\\n\\n              Don't waste time to write README, use readme-ai instead\\n              \\n#ai\\n#readme\\n#openai\\n\\n\\n\\n              C#: Azure Open AI and Function Calling\\n              \\n#azure\\n#openai\\n#functioncalling\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            💎 DEV Diamond Sponsors\\n        \\n\\n            Thank you to our Diamond Sponsors for supporting the DEV Community\\n        \\n\\n\\n\\n\\n\\nGoogle AI is the official AI Model and Platform Partner of DEV\\n\\n\\n\\n\\n\\nNeon is the official database partner of DEV\\n\\n\\n\\n\\n\\nAlgolia is the official search partner of DEV\\n\\n\\n\\n\\n\\nDEV Community — A space to discuss and keep up software development and manage your software career\\n    \\n\\n\\n\\n      Home\\n    \\n\\n\\n\\n\\n      About\\n    \\n\\n\\n\\n\\n      Contact\\n    \\n\\n\\n\\n\\n\\n\\n      Code of Conduct\\n    \\n\\n\\n\\n\\n      Privacy Policy\\n    \\n\\n\\n\\n\\n      Terms of Use\\n    \\n\\n\\n\\n\\nBuilt on Forem — the open source software that powers DEV and other inclusive communities.\\nMade with love and Ruby on Rails. DEV Community © 2016 - 2025.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          We're a place where coders share, stay up-to-date and grow their careers.\\n      \\n\\n\\n\\n        Log in\\n      \\n\\n        Create account\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def extract_text_from_url(url):\n",
        "\tresponse = requests.get(url)\n",
        "\tsoup = BeautifulSoup(response.text, 'html.parser')\n",
        "\ttext = soup.get_text()\n",
        "\treturn text\n",
        "\n",
        "\tif response.status_code == 200:\n",
        "\t\tsoup = BeautifulSoup(response.text, 'html.parser')\n",
        "\t\tfor script_or_style in soup(['script', 'style']):\n",
        "\t\t\tscript_or_style.decompose()\n",
        "\t\ttexto = soup.get_text(separator = ' ')\n",
        "\n",
        "\t\tlinhas = (line.strip() for line in texto.splitlines())\n",
        "\t\tparts = (phrase.strip() for line in linhas for phrase in line.split(\" \"))\n",
        "\t\ttexto_limpo = '\\n'.join(part for part in parts if part)\n",
        "\telse:\n",
        "\t\tprint(f\"Failes to fetch the URL. Status code: {response.status_code}\")\n",
        "\t\treturn None\n",
        "\n",
        "\ttext = soup.get_text()\n",
        "\treturn text\n",
        "\n",
        "extract_text_from_url('https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4kn2Ym3kmnZU"
      },
      "outputs": [],
      "source": [
        "client = AzureChatOpenAI(\n",
        "  azure_endpoint = 'https://blabla.openai.azure.com',\n",
        "  api_key = '3xxxxx5xx5b4cxxx9180xxxxxxxx48b' ,\n",
        "  api_version = \"2025-01-01-preview\",\n",
        "  deployment_name = 'gpt-4.1-mini',\n",
        "  max_retries = 0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zndBvGXAnyhP"
      },
      "outputs": [],
      "source": [
        "def translate_article(text, lang):\n",
        "\n",
        "\tmessages = [\n",
        "    {\"role\": \"system\", \"content\": \"Você atua como tradutor de textos.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"Traduza o texto a seguir para o idioma {lang} e responda em markdown:\\n\\n{text}\"}\n",
        "]\n",
        "\n",
        "\n",
        "\tresponse = client.invoke(messages)\n",
        "\tprint(response.content)\n",
        "\n",
        "\treturn response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "sU-lQ6NSoPK0",
        "outputId": "1951f0bc-c5d3-40ac-c66f-e63f92e1b3e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vamos ver se o implante foi bem-sucedido.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Vamos ver se o implante foi bem-sucedido.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate_article(\"Let's see if the deployment was succeeded.\", \"portugues\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifZl69Akprhj",
        "outputId": "cd6bb57b-119b-45f5-dda1-c402b69ab7ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```markdown\n",
            "# Azure Open AI em VNet - DEV Community\n",
            "\n",
            "## Kenichiro Nakamura  \n",
            "Publicado em 12 de outubro de 2023\n",
            "\n",
            "---\n",
            "\n",
            "Os modelos GPT estão hospedados em múltiplos provedores de serviço atualmente, e o Microsoft Azure é um deles.  \n",
            "Apesar dos modelos em si serem os mesmos, existem muitas diferenças, incluindo:\n",
            "\n",
            "- custo  \n",
            "- funcionalidades  \n",
            "- tipos de modelos e versões  \n",
            "- localização geográfica  \n",
            "- segurança  \n",
            "- suporte  \n",
            "- etc.\n",
            "\n",
            "Um dos aspectos mais importantes ao usá-los em um ambiente empresarial é, claro, a **segurança**.  \n",
            "Usando os recursos de segurança de rede do Azure com o Azure Open AI, os clientes podem consumir o serviço Open AI a partir da VNet, ou seja, nenhuma informação transita pela internet pública.\n",
            "\n",
            "---\n",
            "\n",
            "## Implantação de Exemplo\n",
            "\n",
            "O repositório de exemplo do Azure fornece arquivos bicep para implantar o Azure Open AI dentro de um ambiente VNet.  \n",
            "GitHub: [openai-enterprise-iac](https://github.com/Azure-Samples/openai-enterprise-iac)  \n",
            "\n",
            "As principais funcionalidades usadas nos arquivos bicep são:\n",
            "\n",
            "- VNet  \n",
            "- Integração da VNet para Web App  \n",
            "- Endpoint Privado para Azure Open AI  \n",
            "- Endpoint Privado para Cognitive Search  \n",
            "- Zona DNS Privada  \n",
            "\n",
            "Ao usar esses recursos, todo o tráfego de saída do Web App é roteado exclusivamente dentro da VNet e todos os nomes são resolvidos em endereços IP privados. O Open AI e o Cognitive Search desativam o endereço IP público, portanto, não há mais um endpoint de interface pública disponível.\n",
            "\n",
            "---\n",
            "\n",
            "## Implantação\n",
            "\n",
            "O arquivo bicep irá implantar os seguintes recursos do Azure.  \n",
            "\n",
            "Vamos implantar e confirmar como funciona. Criei um grupo de recursos na região East US para meus próprios testes.\n",
            "\n",
            "```bash\n",
            "git clone https://github.com/Azure-Samples/openai-enterprise-iac\n",
            "cd openai-enterprise-iac\n",
            "az group create -n openaitest -l eastus\n",
            "az deployment group create -g openaitest -f ./infra/main.bicep\n",
            "```\n",
            "\n",
            "Após executar o comando acima, vejo o início da implantação.  \n",
            "Aguarde até a implantação ser concluída.\n",
            "\n",
            "---\n",
            "\n",
            "## Teste\n",
            "\n",
            "Vamos verificar se a implantação foi bem-sucedida.\n",
            "\n",
            "### Azure Open AI\n",
            "\n",
            "Primeiro, vamos testar o acesso público.  \n",
            "Eu consegui criar a implantação sem nenhum problema. Mas ao tentar usar o Chat playground no portal do Azure, recebi o seguinte erro.  \n",
            "\n",
            "E quanto ao acesso via Web API?  \n",
            "A partir da ferramenta avançada do App Service, faço login na sessão Bash e primeiramente executo um ping para a URL do serviço.\n",
            "\n",
            "O endereço IP privado atribuído ao Endpoint Privado é retornado.  \n",
            "Então uso o comando `curl` para enviar uma requisição ao endpoint.\n",
            "\n",
            "---\n",
            "\n",
            "## Comentários Principais\n",
            "\n",
            "(Sem comentários no momento)\n",
            "\n",
            "---\n",
            "\n",
            "## Sobre o Autor\n",
            "\n",
            "**Kenichiro Nakamura**  \n",
            "- Usuário confiável  \n",
            "- Entrou em 3 de fevereiro de 2018  \n",
            "\n",
            "---\n",
            "\n",
            "## Outros posts de Kenichiro Nakamura  \n",
            "- Azure ML Prompt flow: Use content safety antes de enviar uma requisição ao LLM  \n",
            "- Não perca tempo para escrever README, use readme-ai  \n",
            "- C#: Azure Open AI e Function Calling  \n",
            "\n",
            "---\n",
            "\n",
            "## Patrocinadores Diamond do DEV Community\n",
            "\n",
            "Obrigado aos nossos Patrocinadores Diamond por apoiarem a comunidade DEV:\n",
            "\n",
            "- Google AI é o parceiro oficial de modelo e plataforma de IA do DEV  \n",
            "- Neon é o parceiro oficial de banco de dados do DEV  \n",
            "- Algolia é o parceiro oficial de busca do DEV  \n",
            "\n",
            "---\n",
            "\n",
            "DEV Community — Um espaço para discutir e acompanhar o desenvolvimento de software e gerenciar sua carreira na área.\n",
            "\n",
            "---\n",
            "\n",
            "**Log in** | **Criar conta**\n",
            "\n",
            "---\n",
            "```\n",
            "```markdown\n",
            "# Azure Open AI em VNet - DEV Community\n",
            "\n",
            "## Kenichiro Nakamura  \n",
            "Publicado em 12 de outubro de 2023\n",
            "\n",
            "---\n",
            "\n",
            "Os modelos GPT estão hospedados em múltiplos provedores de serviço atualmente, e o Microsoft Azure é um deles.  \n",
            "Apesar dos modelos em si serem os mesmos, existem muitas diferenças, incluindo:\n",
            "\n",
            "- custo  \n",
            "- funcionalidades  \n",
            "- tipos de modelos e versões  \n",
            "- localização geográfica  \n",
            "- segurança  \n",
            "- suporte  \n",
            "- etc.\n",
            "\n",
            "Um dos aspectos mais importantes ao usá-los em um ambiente empresarial é, claro, a **segurança**.  \n",
            "Usando os recursos de segurança de rede do Azure com o Azure Open AI, os clientes podem consumir o serviço Open AI a partir da VNet, ou seja, nenhuma informação transita pela internet pública.\n",
            "\n",
            "---\n",
            "\n",
            "## Implantação de Exemplo\n",
            "\n",
            "O repositório de exemplo do Azure fornece arquivos bicep para implantar o Azure Open AI dentro de um ambiente VNet.  \n",
            "GitHub: [openai-enterprise-iac](https://github.com/Azure-Samples/openai-enterprise-iac)  \n",
            "\n",
            "As principais funcionalidades usadas nos arquivos bicep são:\n",
            "\n",
            "- VNet  \n",
            "- Integração da VNet para Web App  \n",
            "- Endpoint Privado para Azure Open AI  \n",
            "- Endpoint Privado para Cognitive Search  \n",
            "- Zona DNS Privada  \n",
            "\n",
            "Ao usar esses recursos, todo o tráfego de saída do Web App é roteado exclusivamente dentro da VNet e todos os nomes são resolvidos em endereços IP privados. O Open AI e o Cognitive Search desativam o endereço IP público, portanto, não há mais um endpoint de interface pública disponível.\n",
            "\n",
            "---\n",
            "\n",
            "## Implantação\n",
            "\n",
            "O arquivo bicep irá implantar os seguintes recursos do Azure.  \n",
            "\n",
            "Vamos implantar e confirmar como funciona. Criei um grupo de recursos na região East US para meus próprios testes.\n",
            "\n",
            "```bash\n",
            "git clone https://github.com/Azure-Samples/openai-enterprise-iac\n",
            "cd openai-enterprise-iac\n",
            "az group create -n openaitest -l eastus\n",
            "az deployment group create -g openaitest -f ./infra/main.bicep\n",
            "```\n",
            "\n",
            "Após executar o comando acima, vejo o início da implantação.  \n",
            "Aguarde até a implantação ser concluída.\n",
            "\n",
            "---\n",
            "\n",
            "## Teste\n",
            "\n",
            "Vamos verificar se a implantação foi bem-sucedida.\n",
            "\n",
            "### Azure Open AI\n",
            "\n",
            "Primeiro, vamos testar o acesso público.  \n",
            "Eu consegui criar a implantação sem nenhum problema. Mas ao tentar usar o Chat playground no portal do Azure, recebi o seguinte erro.  \n",
            "\n",
            "E quanto ao acesso via Web API?  \n",
            "A partir da ferramenta avançada do App Service, faço login na sessão Bash e primeiramente executo um ping para a URL do serviço.\n",
            "\n",
            "O endereço IP privado atribuído ao Endpoint Privado é retornado.  \n",
            "Então uso o comando `curl` para enviar uma requisição ao endpoint.\n",
            "\n",
            "---\n",
            "\n",
            "## Comentários Principais\n",
            "\n",
            "(Sem comentários no momento)\n",
            "\n",
            "---\n",
            "\n",
            "## Sobre o Autor\n",
            "\n",
            "**Kenichiro Nakamura**  \n",
            "- Usuário confiável  \n",
            "- Entrou em 3 de fevereiro de 2018  \n",
            "\n",
            "---\n",
            "\n",
            "## Outros posts de Kenichiro Nakamura  \n",
            "- Azure ML Prompt flow: Use content safety antes de enviar uma requisição ao LLM  \n",
            "- Não perca tempo para escrever README, use readme-ai  \n",
            "- C#: Azure Open AI e Function Calling  \n",
            "\n",
            "---\n",
            "\n",
            "## Patrocinadores Diamond do DEV Community\n",
            "\n",
            "Obrigado aos nossos Patrocinadores Diamond por apoiarem a comunidade DEV:\n",
            "\n",
            "- Google AI é o parceiro oficial de modelo e plataforma de IA do DEV  \n",
            "- Neon é o parceiro oficial de banco de dados do DEV  \n",
            "- Algolia é o parceiro oficial de busca do DEV  \n",
            "\n",
            "---\n",
            "\n",
            "DEV Community — Um espaço para discutir e acompanhar o desenvolvimento de software e gerenciar sua carreira na área.\n",
            "\n",
            "---\n",
            "\n",
            "**Log in** | **Criar conta**\n",
            "\n",
            "---\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "url = 'https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo'\n",
        "text = extract_text_from_url(url)\n",
        "article = translate_article(text, \"portugues\")\n",
        "print(article)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
